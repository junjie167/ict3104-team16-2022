{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf17a53",
   "metadata": {},
   "source": [
    "# <u>T16 HOI HUB</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002b842",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b76b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd853c0",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046cd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = os.listdir('data/video')\n",
    "\n",
    "list_of_video = {}\n",
    "for video in video_folder:\n",
    "    # remove hidden file especially for macOS\n",
    "    if not video.startswith('.'):\n",
    "        list_of_video[video] = video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753b833",
   "metadata": {},
   "source": [
    "## Create Caption files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d134d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read action and frame object from file\n",
    "def readCaptionFile(filename,videoName):\n",
    "    # Opening JSON file\n",
    "    f = open(filename)\n",
    "\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Iterating through the json\n",
    "    # Closing file\n",
    "    f.close()\n",
    "    return data[videoName][\"actions\"]\n",
    "\n",
    "# convert frame to time\n",
    "def convertFrameToTime(frame):\n",
    "    seconds = int(frame/25)\n",
    "    minutes = \"00\"\n",
    "    if seconds >= 60:\n",
    "        minutes = str(seconds // 60)\n",
    "        seconds = seconds % 60\n",
    "    if len(minutes) == 1:\n",
    "        minutes = \"0\" + minutes\n",
    "    seconds = str(seconds)\n",
    "    #may need handle hour\n",
    "    if len(seconds) == 1:\n",
    "        seconds = \"0\" + seconds \n",
    "    return (minutes + \":\" + seconds + \".000\")\n",
    "\n",
    "# read reference text from txt file\n",
    "def readReferenceFile(refFile):\n",
    "    referenceDict = {}\n",
    "    with open(refFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for i in lines:\n",
    "        x = i.split()\n",
    "        referenceDict[str(x[0])] = x[1]\n",
    "    return referenceDict\n",
    "\n",
    "# create caption file\n",
    "def formatCaptionFile(captionList, reference, captionPath):\n",
    "    start = \"WEBVTT\\n\\n\"\n",
    "    captions = []\n",
    "    for i in captionList:\n",
    "        text = reference[str(i[0])]\n",
    "        lines = convertFrameToTime(i[1]) + \" --> \" + convertFrameToTime(i[2]) + \"\\n\" + text + \"\\n\\n\"\n",
    "        captions.append(lines)\n",
    "    f = open(captionPath, \"w\")\n",
    "    f.write(start)\n",
    "    f.writelines(captions)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a51743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab004fd950f44b99c30cde30832276d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos', options={'P02T01C06.mp4': 'P02T01C06.mp4', 'P02T01C07.mp4': 'P02T01C07.mp4'}, vâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_dropdown = widgets.Dropdown(\n",
    "    options = list_of_video,\n",
    "    description = 'Videos',\n",
    ")\n",
    "\n",
    "video_src = 'data/video/' + video_dropdown.value\n",
    "\n",
    "def play_video(video_src,caption_src):\n",
    "    video = io.open(video_src, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return(HTML(data='''<video width=\"650\" height=\"360\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        <track kind=\"captions\" src={1} srclang=\"en\" label=\"English\" default>\n",
    "        </video>'''.format(encoded.decode('ascii'),caption_src)))\n",
    "\n",
    "\n",
    "# video dropdown onchange function\n",
    "def video_on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "        global video_src \n",
    "        video_src = 'data/video/'+ video_dropdown.value\n",
    "        \n",
    "          \n",
    "# display video dropdown\n",
    "video_dropdown.observe(video_on_change)\n",
    "display(video_dropdown) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa9208bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_labels.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m videoName \u001b[38;5;241m=\u001b[39m video_dropdown\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#location of reference are place at root\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m ref \u001b[38;5;241m=\u001b[39m \u001b[43mreadReferenceFile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_labels.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# may need change the caption path to dynamic\u001b[39;00m\n\u001b[0;32m      6\u001b[0m captionPath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/video/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m videoName[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.vtt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mreadReferenceFile\u001b[1;34m(refFile)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadReferenceFile\u001b[39m(refFile):\n\u001b[0;32m     32\u001b[0m     referenceDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrefFile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     34\u001b[0m         lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m lines:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_labels.txt'"
     ]
    }
   ],
   "source": [
    "# caption\n",
    "videoName = video_dropdown.value.split(\".\")\n",
    "#location of reference are place at root\n",
    "ref = readReferenceFile('all_labels.txt')\n",
    "# may need change the caption path to dynamic\n",
    "captionPath = \"data/video/\" + videoName[0] + \".vtt\"\n",
    "# model result file should be some directory, here using root \n",
    "captionList = readCaptionFile('smarthome_CS_51.json',videoName[0])\n",
    "formatCaptionFile(captionList,ref,captionPath)\n",
    "\n",
    "\n",
    "video = video_src.split('/')[-1]\n",
    "print(\"Currently playing : \" + video)\n",
    "play_video(video_src, captionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56ee9a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e0a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a6e5012",
   "metadata": {},
   "source": [
    "## Training HOI ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d461e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db4bbbf3",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc661c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5704913ca0f43789d0dc073452ec263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='evaluation', options={'PDAN_TSU_RGB': 'PDAN_TSU_RGB'}, value='PDAN_TSU_RGB')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pretrained_model_folder = os.listdir('data/pretrained_model')\n",
    "\n",
    "list_of_ptModels = {}\n",
    "for model in pretrained_model_folder:\n",
    "    # remove hidden file especially for macOS\n",
    "    if not model.startswith('.'):\n",
    "        list_of_ptModels[model] = model\n",
    "\n",
    "evaluation_dropdown = widgets.Dropdown(\n",
    "    options = list_of_ptModels,\n",
    "    description = 'evaluation',\n",
    ")\n",
    "\n",
    "model_src = 'data/pretrained_model/' + evaluation_dropdown.value\n",
    "\n",
    "# evaluation dropdown onchange function\n",
    "def evaluation_on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "        global model_src \n",
    "        model_src = 'data/video/'+ evaluation_dropdown.value\n",
    "        \n",
    "          \n",
    "# display evaluation dropdown\n",
    "evaluation_dropdown.observe(evaluation_on_change)\n",
    "display(evaluation_dropdown) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7125e28f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ngjun\\Downloads\\ict3104-team16-2022\\test.py\", line 6, in <module>\n",
      "    import torch\n",
      "  File \"C:\\Users\\ngjun\\miniconda3\\envs\\ict3104\\lib\\site-packages\\torch\\__init__.py\", line 124, in <module>\n",
      "    raise err\n",
      "OSError: [WinError 1455] The paging file is too small for this operation to complete. Error loading \"C:\\Users\\ngjun\\miniconda3\\envs\\ict3104\\lib\\site-packages\\torch\\lib\\cudnn_adv_infer64_8.dll\" or one of its dependencies.\n"
     ]
    }
   ],
   "source": [
    "###Evaluate Model\n",
    "run = f\"\"\n",
    "!python test.py -dataset TSU -mode rgb -split_setting CS -model PDAN -train False -num_channel 512 -lr 0.0002 -kernelsize 3 -APtype map -epoch 140 -batch_size 1 -comp_info TSU_CS_RGB_PDAN -load_model $model_src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d86b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
