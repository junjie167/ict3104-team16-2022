{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf17a53",
   "metadata": {},
   "source": [
    "# <u>T16 HOI HUB</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002b842",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b76b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from tqdm.notebook import trange, tqdm ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd853c0",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046cd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = os.listdir('data/video')\n",
    "\n",
    "list_of_video = {}\n",
    "for video in video_folder:\n",
    "    # remove hidden file especially for macOS\n",
    "    if not video.startswith('.'):\n",
    "        list_of_video[video] = video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753b833",
   "metadata": {},
   "source": [
    "## Create Caption files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d134d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read action and frame object from file\n",
    "def readCaptionFile(filename,videoName):\n",
    "    # Opening JSON file\n",
    "    f = open(filename)\n",
    "\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Iterating through the json\n",
    "    # Closing file\n",
    "    f.close()\n",
    "    return data[videoName][\"actions\"]\n",
    "\n",
    "# convert frame to time\n",
    "def convertFrameToTime(frame):\n",
    "    seconds = int(frame/25)\n",
    "    minutes = \"00\"\n",
    "    if seconds >= 60:\n",
    "        minutes = str(seconds // 60)\n",
    "        seconds = seconds % 60\n",
    "    if len(minutes) == 1:\n",
    "        minutes = \"0\" + minutes\n",
    "    seconds = str(seconds)\n",
    "    #may need handle hour\n",
    "    if len(seconds) == 1:\n",
    "        seconds = \"0\" + seconds \n",
    "    return (minutes + \":\" + seconds + \".000\")\n",
    "\n",
    "# read reference text from txt file\n",
    "def readReferenceFile(refFile):\n",
    "    referenceDict = {}\n",
    "    with open(refFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for i in lines:\n",
    "        x = i.split()\n",
    "        referenceDict[str(x[0])] = x[1]\n",
    "    return referenceDict\n",
    "\n",
    "# create caption file\n",
    "def formatCaptionFile(captionList, reference, captionPath):\n",
    "    start = \"WEBVTT\\n\\n\"\n",
    "    captions = []\n",
    "    for i in captionList:\n",
    "        text = reference[str(i[0])]\n",
    "        lines = convertFrameToTime(i[1]) + \" --> \" + convertFrameToTime(i[2]) + \"\\n\" + text + \"\\n\\n\"\n",
    "        captions.append(lines)\n",
    "    f = open(captionPath, \"w\")\n",
    "    f.write(start)\n",
    "    f.writelines(captions)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a51743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_dropdown = widgets.Dropdown(\n",
    "    options = list_of_video,\n",
    "    description = 'Videos',\n",
    ")\n",
    "\n",
    "video_src = 'data/video/' + video_dropdown.value\n",
    "\n",
    "def play_video(video_src,caption_src):\n",
    "    video = io.open(video_src, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return(HTML(data='''<video width=\"650\" height=\"360\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        <track kind=\"captions\" src={1} srclang=\"en\" label=\"English\" default>\n",
    "        </video>'''.format(encoded.decode('ascii'),caption_src)))\n",
    "\n",
    "\n",
    "# video dropdown onchange function\n",
    "def video_on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "        global video_src \n",
    "        video_src = 'data/video/'+ video_dropdown.value\n",
    "        \n",
    "          \n",
    "# display video dropdown\n",
    "video_dropdown.observe(video_on_change)\n",
    "display(video_dropdown) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9208bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption\n",
    "videoName = video_dropdown.value.split(\".\")\n",
    "#location of reference are place at root\n",
    "ref = readReferenceFile('all_labels.txt')\n",
    "# may need change the caption path to dynamic\n",
    "captionPath = \"data/video/\" + videoName[0] + \".vtt\"\n",
    "# model result file should be some directory, here using root \n",
    "captionList = readCaptionFile('smarthome_CS_51.json',videoName[0])\n",
    "formatCaptionFile(captionList,ref,captionPath)\n",
    "\n",
    "\n",
    "video = video_src.split('/')[-1]\n",
    "print(\"Currently playing : \" + video)\n",
    "play_video(video_src, captionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f17fab",
   "metadata": {},
   "source": [
    "## Extract i3D features from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831d5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2247ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the desired videos are selected\n",
    "# video_paths: list[str] = [\"../data/RGB_Video_MP4/P02T01C06.mp4\"]\n",
    "video_paths = open(\"HOI/I3D/video_list.txt\").readlines()\n",
    "video_paths = list(map(lambda video: \"../data/RGB_Video_MP4/{0}.mp4\".format(video.strip()), video_paths))\n",
    "# TODO: choose a project-relative directory\n",
    "output_path = \"/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/data/RGB_i3d_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3d_defaults = OmegaConf.load(Path(\"feature_extractor/configs/i3d.yml\"))\n",
    "i3d_config = OmegaConf.merge(i3d_defaults, OmegaConf.create({\n",
    "    \"feature_type\": \"i3d\",\n",
    "    \"streams\": \"rgb\",\n",
    "    \"output_path\": output_path,\n",
    "    \"video_paths\": video_paths,\n",
    "    \"on_extraction\": \"save_numpy\",\n",
    "    \"stack_size\": 16,\n",
    "    \"step_size\": 16\n",
    "}))\n",
    "extractor = models.ExtractI3D(i3d_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dd2182",
   "metadata": {},
   "outputs": [],
   "source": [
    "for video in tqdm(video_paths, desc=\"videos extracted\"):\n",
    "    extractor._extract(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56ee9a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e0a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ccb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Example: to be modified\n",
    "# lets say TSU has been selected\n",
    "from TSU_PDAN import HOI_PDAN\n",
    "from HOI.smarthome_i3d_per_video import TSU as Dataset\n",
    "from HOI.smarthome_i3d_per_video import TSU_collate_fn as collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bad61a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: v-iashin\n",
    "# lets say TSU smarthome is then selected (in practice, a custom json is generated depending on what specific videos are selected)\n",
    "val_dataset = Dataset(\"../data/RGB_i3d_test/smarthome_CS_51.json\", 'testing', \"../data/RGB_i3d_test\", 1, 51)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "                                                pin_memory=True, collate_fn=collate_fn)\n",
    "# val_dataloader.root = args.rgb_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d14c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelrunner = HOI_PDAN()\n",
    "modelrunner.PDAN_training_parameters()\n",
    "modelrunner.model.load_state_dict(torch.load(\"data/pretrained_model/PDAN/weight_epoch_1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a5a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = None\n",
    "# note: this doesn't appear to show up properly in vscode\n",
    "with tqdm(val_dataloader, unit='batch') as progressive_loader:\n",
    "    result = modelrunner.evaluate(progressive_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e5012",
   "metadata": {},
   "source": [
    "## Training HOI ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d461e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1751661",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(\"../data/RGB_i3d_test/smarthome_CS_51.json\", 'training', \"../data/RGB_i3d_test\", 1, 51)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "                                                pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8447ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with trange(0,5, unit='epoch', desc='epochs') as epoch_range:\n",
    "    for model in modelrunner.train(\n",
    "        train_dataloader=train_dataloader, \n",
    "        val_dataloader=val_dataloader, \n",
    "        epoch_range=epoch_range\n",
    "    ):\n",
    "        # save model snapshot at this epoch\n",
    "        torch.save(model.state_dict(),'./data/pretrained_model/PDAN/weight_epoch_'+str(modelrunner.epoch))\n",
    "        torch.save(model,'./data/pretrained_model/PDAN/model_epoch_'+str(modelrunner.epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bbbf3",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989caaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Evaluate Model\n",
    "pretrained_model_folder = os.listdir('data/pretrained_model')\n",
    "\n",
    "list_of_ptModels = {}\n",
    "for model in pretrained_model_folder:\n",
    "    # remove hidden file especially for macOS\n",
    "    if not model.startswith('.'):\n",
    "        list_of_ptModels[model] = model\n",
    "\n",
    "evaluation_dropdown = widgets.Dropdown(\n",
    "    options = list_of_ptModels,\n",
    "    description = 'evaluation',\n",
    ")\n",
    "\n",
    "model_src = 'data/pretrained_model/' + evaluation_dropdown.value\n",
    "\n",
    "# evaluation dropdown onchange function\n",
    "def evaluation_on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "        global model_src \n",
    "        model_src = 'data/video/'+ evaluation_dropdown.value\n",
    "        \n",
    "          \n",
    "# display evaluation dropdown\n",
    "evaluation_dropdown.observe(evaluation_on_change)\n",
    "display(evaluation_dropdown) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc661c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = f\"python test.py -dataset TSU -mode rgb -split_setting CS -model PDAN -train False -num_channel 512 -lr 0.0002 -kernelsize 3 -APtype map -batch_size 1 -comp_info TSU_CS_RGB_PDAN -load_model {model_src} -video {video_dropdown.value}\"\n",
    "!{run}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7549077eaa34f2c19a3fecd34550ed512945c2d9cf1d3fcbaf38bfefc0e9a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
