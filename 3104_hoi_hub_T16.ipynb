{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf17a53",
   "metadata": {},
   "source": [
    "# <u>T16 HOI HUB</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002b842",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b76b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import io\n",
    "import base64\n",
    "import json\n",
    "from tqdm.notebook import trange, tqdm ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd853c0",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "046cd00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_folder = os.listdir('data/video')\n",
    "\n",
    "list_of_video = {}\n",
    "for video in video_folder:\n",
    "    # remove hidden file especially for macOS\n",
    "    if not video.startswith('.'):\n",
    "        list_of_video[video] = video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753b833",
   "metadata": {},
   "source": [
    "## Create Caption files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d134d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read action and frame object from file\n",
    "def readCaptionFile(filename,videoName):\n",
    "    # Opening JSON file\n",
    "    f = open(filename)\n",
    "\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n",
    "\n",
    "    # Iterating through the json\n",
    "    # Closing file\n",
    "    f.close()\n",
    "    return data[videoName][\"actions\"]\n",
    "\n",
    "# convert frame to time\n",
    "def convertFrameToTime(frame):\n",
    "    seconds = int(frame/25)\n",
    "    minutes = \"00\"\n",
    "    if seconds >= 60:\n",
    "        minutes = str(seconds // 60)\n",
    "        seconds = seconds % 60\n",
    "    if len(minutes) == 1:\n",
    "        minutes = \"0\" + minutes\n",
    "    seconds = str(seconds)\n",
    "    #may need handle hour\n",
    "    if len(seconds) == 1:\n",
    "        seconds = \"0\" + seconds \n",
    "    return (minutes + \":\" + seconds + \".000\")\n",
    "\n",
    "# read reference text from txt file\n",
    "def readReferenceFile(refFile):\n",
    "    referenceDict = {}\n",
    "    with open(refFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for i in lines:\n",
    "        x = i.split()\n",
    "        referenceDict[str(x[0])] = x[1]\n",
    "    return referenceDict\n",
    "\n",
    "# create caption file\n",
    "def formatCaptionFile(captionList, reference, captionPath):\n",
    "    start = \"WEBVTT\\n\\n\"\n",
    "    captions = []\n",
    "    for i in captionList:\n",
    "        text = reference[str(i[0])]\n",
    "        lines = convertFrameToTime(i[1]) + \" --> \" + convertFrameToTime(i[2]) + \"\\n\" + text + \"\\n\\n\"\n",
    "        captions.append(lines)\n",
    "    f = open(captionPath, \"w\")\n",
    "    f.write(start)\n",
    "    f.writelines(captions)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a51743c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d047487733444a7a8cf8159c22404dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Videos', options={'P02T01C07.vtt': 'P02T01C07.vtt', 'P02T01C06.vtt': 'P02T01C06.vtt', 'P…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_dropdown = widgets.Dropdown(\n",
    "    options = list_of_video,\n",
    "    description = 'Videos',\n",
    ")\n",
    "\n",
    "video_src = 'data/video/' + video_dropdown.value\n",
    "\n",
    "def play_video(video_src,caption_src):\n",
    "    video = io.open(video_src, 'r+b').read()\n",
    "    encoded = base64.b64encode(video)\n",
    "    return(HTML(data='''<video width=\"650\" height=\"360\" controls>\n",
    "        <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "        <track kind=\"captions\" src={1} srclang=\"en\" label=\"English\" default>\n",
    "        </video>'''.format(encoded.decode('ascii'),caption_src)))\n",
    "\n",
    "\n",
    "# video dropdown onchange function\n",
    "def video_on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        change['new']\n",
    "        global video_src \n",
    "        video_src = 'data/video/'+ video_dropdown.value\n",
    "        \n",
    "          \n",
    "# display video dropdown\n",
    "video_dropdown.observe(video_on_change)\n",
    "display(video_dropdown) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9208bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caption\n",
    "videoName = video_dropdown.value.split(\".\")\n",
    "#location of reference are place at root\n",
    "ref = readReferenceFile('all_labels.txt')\n",
    "# may need change the caption path to dynamic\n",
    "captionPath = \"data/video/\" + videoName[0] + \".vtt\"\n",
    "# model result file should be some directory, here using root \n",
    "captionList = readCaptionFile('smarthome_CS_51.json',videoName[0])\n",
    "formatCaptionFile(captionList,ref,captionPath)\n",
    "\n",
    "\n",
    "video = video_src.split('/')[-1]\n",
    "print(\"Currently playing : \" + video)\n",
    "play_video(video_src, captionPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f17fab",
   "metadata": {},
   "source": [
    "## Extract i3D features from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831d5daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ebc8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2247ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after the desired videos are selected\n",
    "video_paths: list[str] = [\"../data/RGB_Video_MP4/P02T01C06.mp4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fae5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "i3d_defaults = OmegaConf.load(Path(\"feature_extractor/configs/i3d.yml\"))\n",
    "i3d_config = OmegaConf.merge(i3d_defaults, OmegaConf.create({\n",
    "    \"feature_type\": \"i3d\",\n",
    "    \"streams\": \"rgb\",\n",
    "    \"output_path\": \"/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/data/RGB_i3d_test\",\n",
    "    \"video_paths\": video_paths,\n",
    "    \"on_extraction\": \"save_numpy\",\n",
    "    \"stack_size\": 16,\n",
    "    \"step_size\": 16\n",
    "}))\n",
    "extractor = models.ExtractI3D(i3d_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4dd2182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a77e1edb3004987bb986d1724b3abf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for video in tqdm(video_paths, desc=\"videos extracted\"):\n",
    "    extractor._extract(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a56ee9a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56e0a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b06ccb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_SEED!!!: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Example: to be modified\n",
    "# lets say TSU has been selected\n",
    "from TSU_PDAN import HOI_PDAN\n",
    "from HOI.smarthome_i3d_per_video import TSU as Dataset\n",
    "from HOI.smarthome_i3d_per_video import TSU_collate_fn as collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bad61a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 536/536 [00:05<00:00, 95.44it/s]\n"
     ]
    }
   ],
   "source": [
    "# TODO: v-iashin\n",
    "# lets say TSU smarthome is then selected (in practice, a custom json is generated depending on what specific videos are selected)\n",
    "val_dataset = Dataset(\"HOI/data/smarthome_CS_51.json\", 'testing', \"../data/RGB_i3d_16frames_64000_SSD\", 1, 51)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "                                                pin_memory=True, collate_fn=collate_fn)\n",
    "# val_dataloader.root = args.rgb_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28d14c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/models.py:88: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.key_conv.weight, mode='fan_out')\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/models.py:89: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.value_conv.weight, mode='fan_out')\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/models.py:90: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(self.query_conv.weight, mode='fan_out')\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/models.py:91: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  init.normal(self.rel_t, 0, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelrunner = HOI_PDAN()\n",
    "modelrunner.PDAN_training_parameters()\n",
    "modelrunner.model.load_state_dict(torch.load(\"HOI/PDAN/weight_epoch_0.0002_35\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86a5a89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b8a12f7bf4d446184bda20042c2726a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/185 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/.venv/lib/python3.10/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/apmeter.py:108: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
      "  rg = torch.range(1, self.scores.size(0)).float()\n",
      "/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/apmeter.py:137: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  ../aten/src/ATen/native/IndexingUtils.h:27.)\n",
      "  ap[k] = precision[truth.byte()].sum() / max(truth.sum(), 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val-map: tensor(34.1454)\n",
      "tensor([46.0981, 53.4290, 44.6538, 51.1127, 43.1801, 46.4834, 37.1899, 31.5516,\n",
      "        42.9660, 21.3682, 17.6236, 13.5470,  1.1666, 41.1923, 49.6549,  3.8188,\n",
      "        19.1954, 59.6317,  5.5071, 71.6044, 36.5219, 74.4247, 54.4266,  3.0952,\n",
      "         0.8215, 62.6654, 35.2815, 45.3404, 59.1798, 16.6004,  7.4304,  0.3018,\n",
      "        33.3252,  3.7282, 43.4654, 88.7000, 37.3753, 18.4837, 25.2225,  5.6187,\n",
      "        71.5390, 33.2785, 13.1370, 62.3055,  3.1802, 80.0095, 72.6115, 29.4839,\n",
      "        18.2610,  3.3478,  1.2794])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(34.1454)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = None\n",
    "# note: this doesn't appear to show up properly in vscode\n",
    "with tqdm(val_dataloader, unit='batch') as progressive_loader:\n",
    "    result = modelrunner.evaluate(progressive_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6e5012",
   "metadata": {},
   "source": [
    "## Training HOI ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d461e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1751661",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 536/536 [00:26<00:00, 19.90it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = Dataset(\"HOI/data/smarthome_CS_51.json\", 'training', \"../data/RGB_i3d_16frames_64000_SSD\", 1, 51)\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4,\n",
    "                                                pin_memory=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8447ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670aebbc9db347fab0bd649c8aa849d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?epoch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d8de550dfc46be9fdf5258d7a3f278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training:   0%|          | 0/351 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a1ca804e4345d1a50bad1c3377971c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validating:   0%|          | 0/185 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_dataloader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_loader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(val_dataloader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidating\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m val_loader:\n\u001b[0;32m----> 4\u001b[0m         [model \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \\\n\u001b[1;32m      5\u001b[0m          modelrunner\u001b[38;5;241m.\u001b[39mtrain(train_dataloader\u001b[38;5;241m=\u001b[39mtrain_loader, val_dataloader\u001b[38;5;241m=\u001b[39mval_loader, epoch_range\u001b[38;5;241m=\u001b[39mepoch_range)]\n",
      "Cell \u001b[0;32mIn [14], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tqdm(train_dataloader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_loader:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tqdm(val_dataloader, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalidating\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m val_loader:\n\u001b[0;32m----> 4\u001b[0m         [model \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \\\n\u001b[1;32m      5\u001b[0m          modelrunner\u001b[38;5;241m.\u001b[39mtrain(train_dataloader\u001b[38;5;241m=\u001b[39mtrain_loader, val_dataloader\u001b[38;5;241m=\u001b[39mval_loader, epoch_range\u001b[38;5;241m=\u001b[39mepoch_range)]\n",
      "File \u001b[0;32m/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/TSU_PDAN.py:61\u001b[0m, in \u001b[0;36mHOI_PDAN.train\u001b[0;34m(self, train_dataloader, val_dataloader, epoch_range)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_range:\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;66;03m# print('Epoch {}/{}'.format(epoch, epochs - 1))\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;66;03m# print('-' * 10)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     probs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 61\u001b[0m     train_map, train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mHOI\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m     prob_val, val_loss, val_map \u001b[38;5;241m=\u001b[39m HOI\u001b[38;5;241m.\u001b[39mtrain\u001b[38;5;241m.\u001b[39mval_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;241m0\u001b[39m, val_dataloader, epoch)\n\u001b[1;32m     63\u001b[0m     probs\u001b[38;5;241m.\u001b[39mappend(prob_val)\n",
      "File \u001b[0;32m/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/train.py:239\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(model, gpu, optimizer, dataloader, epoch)\u001b[0m\n\u001b[1;32m    236\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    237\u001b[0m num_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 239\u001b[0m outputs, loss, probs, err \u001b[38;5;241m=\u001b[39m \u001b[43mrun_network\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    240\u001b[0m apm\u001b[38;5;241m.\u001b[39madd(probs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m], data[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    241\u001b[0m error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m err\u001b[38;5;241m.\u001b[39mdata\n",
      "File \u001b[0;32m/media/starlight/2c72c05a-ec96-4c96-ba3c-50ae4bc6730b/home/starlight/TSU/ict3104-team16-2022/HOI/train.py:190\u001b[0m, in \u001b[0;36mrun_network\u001b[0;34m(model, data, gpu, epoch, baseline, modelkind)\u001b[0m\n\u001b[1;32m    188\u001b[0m inputs, mask, labels, other \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# wrap them in Variable\u001b[39;00m\n\u001b[0;32m--> 190\u001b[0m inputs \u001b[38;5;241m=\u001b[39m Variable(\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgpu\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m mask \u001b[38;5;241m=\u001b[39m Variable(mask\u001b[38;5;241m.\u001b[39mcuda(gpu))\n\u001b[1;32m    192\u001b[0m labels \u001b[38;5;241m=\u001b[39m Variable(labels\u001b[38;5;241m.\u001b[39mcuda(gpu))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with trange(0,5, unit='epoch', desc='epochs') as epoch_range:\n",
    "    with tqdm(train_dataloader, unit='batch', desc='training') as train_loader:\n",
    "        with tqdm(val_dataloader, unit='batch', desc='validating') as val_loader:\n",
    "            [model for model in \\\n",
    "             modelrunner.train(train_dataloader=train_loader, val_dataloader=val_loader, epoch_range=epoch_range)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4bbbf3",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc661c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "a7549077eaa34f2c19a3fecd34550ed512945c2d9cf1d3fcbaf38bfefc0e9a04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
